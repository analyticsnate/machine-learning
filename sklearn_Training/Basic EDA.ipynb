{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA\n",
    "- splitting datasets into train/test\n",
    "- using KNeighborsRegressor\n",
    "- using Mean Squared Error to compare estimated results to test results\n",
    "- normalize data using StandardScaler() and RobustScaler()\n",
    "- create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building New Features\n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/datasets\n",
    "from sklearn import datasets \n",
    "\n",
    "# used to split datasets for machine learning\n",
    "# https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "# The MSE is a measure of the quality of an estimator\n",
    "# https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\Nate\\scikit_learn_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'California housing dataset.\\n\\nThe original database is available from StatLib\\n\\n    http://lib.stat.cmu.edu/datasets/\\n\\nThe data contains 20,640 observations on 9 variables.\\n\\nThis dataset contains the average house value as target variable\\nand the following input variables (features): average income,\\nhousing average age, average rooms, average bedrooms, population,\\naverage occupation, latitude, and longitude in that order.\\n\\nReferences\\n----------\\n\\nPace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\nStatistics and Probability Letters, 33 (1997) 291-297.\\n\\n',\n",
       " 'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali = datasets.california_housing.fetch_california_housing()\n",
    "cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cali['data']\n",
    "Y = cali['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split cali dataset X,Y into train & test datasets\n",
    "# train size of 0.8 means we're using 0.8 of the datasets\n",
    "# to train and the rest to test our algorithm\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/neighbors.html\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build KNN Regressor model here\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model to predict test values\n",
    "Y_est = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  1.1151279812969894\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE = \", mean_squared_error(Y_test, Y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train_test_split to split dataset\n",
    "# pass in X_train and Y_train to fit the regressor\n",
    "# use regressor with X_test to estimate/predict Y_est\n",
    "# use MSE to compare Y_est to Y_test\n",
    "\n",
    "def KN_Predict(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "    regressor = KNeighborsRegressor()\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    Y_est = regressor.predict(X_test)\n",
    "    return mean_squared_error(Y_test, Y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1159417094115245"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = [] # list of MAE values\n",
    "n = 10 # iterations\n",
    "\n",
    "# run the model n number of times\n",
    "for i in range(0, n):\n",
    "    MAE.append(KN_Predict(cali['data'], cali['target']))\n",
    "    \n",
    "np.mean(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize X values using z-normalization\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train_test_split to split dataset\n",
    "# scale X data using StandardScaler()\n",
    "# pass in X_train and Y_train to fit the regressor\n",
    "# use regressor with X_test to estimate/predict Y_est\n",
    "# use MSE to compare Y_est to Y_test\n",
    "\n",
    "def KN_Predict_Scaled(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    regressor = KNeighborsRegressor()\n",
    "    regressor.fit(X_train_scaled, Y_train)\n",
    "    Y_est = regressor.predict(X_test_scaled)\n",
    "    return mean_squared_error(Y_test, Y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41477224514685007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = [] # list of MAE values\n",
    "n = 10 # iterations\n",
    "\n",
    "# run the model n number of times\n",
    "for i in range(0, n):\n",
    "    MAE.append(KN_Predict_Scaled(cali['data'], cali['target']))\n",
    "    \n",
    "np.mean(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE is the square of how different the estimates are\n",
    "# relative to the actuals, basically how good your\n",
    "# ML model predicts the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RobustScaler is better for datasets that have large outliers\n",
    "# how do we determine if the dataset has large outliers systematically?\n",
    "# generally try both scalers and see which one has better (lower) MSE\n",
    "scaler2 = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train_test_split to split dataset\n",
    "# scale X data using RobustScaler()\n",
    "# pass in X_train and Y_train to fit the regressor\n",
    "# use regressor with X_test to estimate/predict Y_est\n",
    "# use MSE to compare Y_est to Y_test\n",
    "\n",
    "def KN_Predict_RobustScaled(X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "    X_train_scaled = scaler2.fit_transform(X_train)\n",
    "    X_test_scaled = scaler2.transform(X_test)\n",
    "    regressor = KNeighborsRegressor()\n",
    "    regressor.fit(X_train_scaled, Y_train)\n",
    "    Y_est = regressor.predict(X_test_scaled)\n",
    "    return mean_squared_error(Y_test, Y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4229417948807613"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = [] # list of MAE values\n",
    "n = 10 # iterations\n",
    "\n",
    "# run the model n number of times\n",
    "for i in range(0, n):\n",
    "    MAE.append(KN_Predict_RobustScaled(cali['data'], cali['target']))\n",
    "    \n",
    "np.mean(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_linear_feat = 5 # AveOccup\n",
    "\n",
    "# new feature is the square root of the 5th feature - AveOccup\n",
    "X_train_new_feat = np.sqrt(X_train[:,non_linear_feat]) # all rows, 5th column\n",
    "\n",
    "# change shape of new feature\n",
    "X_train_new_feat.shape = (X_train_new_feat.shape[0], 1)\n",
    "\n",
    "# add new feature to the X_train ndarray using horizontal stacking\n",
    "# this works as long as arrays are same number of rows\n",
    "X_train_extended = np.hstack([X_train, X_train_new_feat])\n",
    "\n",
    "# do same steps for X_test\n",
    "X_test_new_feat = np.sqrt(X_test[:,non_linear_feat])\n",
    "X_test_new_feat.shape = (X_test_new_feat.shape[0], 1)\n",
    "X_test_extended = np.hstack([X_test, X_test_new_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extended_scaled = scaler.fit_transform(X_train_extended)\n",
    "X_test_extended_scaled = scaler.transform(X_test_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train_extended_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  0.3504576041648188\n"
     ]
    }
   ],
   "source": [
    "Y_est = regressor.predict(X_test_extended_scaled)\n",
    "print(\"MAE = \", mean_squared_error(Y_test, Y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
